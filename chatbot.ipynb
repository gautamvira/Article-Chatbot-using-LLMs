{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import OllamaEmbeddings, OllamaLLM\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "import os, shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing database and emebedding for queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(model='nomic-embed-text')\n",
    "database = Chroma(persist_directory='./database', embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Template for prompt to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Answer the question based only on the following context: {context}\n",
    "\n",
    "---\n",
    "\n",
    "Answer the question based only on the above context: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding relevant chunks to be fed to llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query texts for llm\n",
    "query_text1 = 'What is Dynamic Time Warping?'\n",
    "query_text2 = 'Is deep learning popular in predictive maintenance?'\n",
    "query_text3 = 'What does Tor traffic mean and/or darknet?'\n",
    "query_text4 = 'Is it difficult to work with coolant temperature data?'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OllamaLLM(model='llama3.1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing LLM with prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic Time Warping (DTW) is a technique that aligns two sequences in a non-linear way to match each other's trends. The idea behind using DTW is that it aligns similar trends between two time series that are being compared, independent of the indices or length of the time series.\n"
     ]
    }
   ],
   "source": [
    "results = database.similarity_search_with_relevance_scores(query_text1, k=4)\n",
    "contexts = '\\n\\n'.join([result.page_content for result, _ in results])\n",
    "template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "prompt = template.format(context=contexts, question=query_text1)\n",
    "response = model.invoke(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the provided context, yes, deep learning is gaining popularity in predictive maintenance. The analysis of works mentioned in this survey suggests that the use of deep learning will become more prevalent as newer methods are developed, such as attention mechanisms, which will enable identifying patterns over large volumes of data and increase accuracy.\n"
     ]
    }
   ],
   "source": [
    "results = database.similarity_search_with_relevance_scores(query_text2, k=4)\n",
    "contexts = '\\n\\n'.join([result.page_content for result, _ in results])\n",
    "template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "prompt = template.format(context=contexts, question=query_text2)\n",
    "response = model.invoke(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the context, \"Tor traffic\" refers to internet traffic that passes through the Onion Router (TOR) network, which is a system designed for anonymity. The TOR network allows users to browse the internet without being tracked or identified.\n",
      "\n",
      "The \"darknet\", on the other hand, is defined as the part of the internet address space that does not interact with other computers in the world, and is often associated with illegal activities due to its anonymous nature. It is said to harbor malicious software and make it difficult to detect such traffic.\n",
      "\n",
      "In this context, Tor traffic is a subset of darknet traffic, which can be malicious or legitimate.\n",
      "['TAVo_Tor_Application_Detection_with_Voting_Critic.pdf-1:7', 'TAVo_Tor_Application_Detection_with_Voting_Critic.pdf-1:6', 'TAVo_Tor_Application_Detection_with_Voting_Critic.pdf-1:5', 'TAVo_Tor_Application_Detection_with_Voting_Critic.pdf-3:1']\n"
     ]
    }
   ],
   "source": [
    "results = database.similarity_search_with_relevance_scores(query_text3, k=4)\n",
    "sources = [result.metadata.get('id') for result, _ in results]\n",
    "contexts = '\\n\\n'.join([result.page_content for result, _ in results])\n",
    "template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "prompt = template.format(context=contexts, question=query_text3)\n",
    "response = model.invoke(prompt)\n",
    "print(response)\n",
    "print(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, it appears that working with coolant temperature data was challenging due to its noisy and inconsistent nature. This is evident in several parts of the text, such as:\n",
      "\n",
      "* The synthetic data failed to capture almost all of the temporal relations, resulting in flat and constantly around 90 degrees Celsius readings.\n",
      "* The real data contained temperature dips.\n",
      "* A larger sampling value (200) was needed to make the noisy coolant temperature data more interpretable.\n",
      "\n",
      "This suggests that the coolant temperature data required special handling and processing to be useful for analysis.\n",
      "['Vira_Gautam_2024_thesis.pdf-59:4', 'Predictive_Maintenance_by_Detection_of_Gradual_Faults_in_an_IoT-Enabled_Public_Bus.pdf-5:4', 'ACM_Journal_TOSN.pdf-9:3', 'ACM_Journal_TOSN.pdf-19:5']\n"
     ]
    }
   ],
   "source": [
    "results = database.similarity_search_with_relevance_scores(query_text4, k=4)\n",
    "sources = [result.metadata.get('id') for result, _ in results]\n",
    "contexts = '\\n\\n'.join([result.page_content for result, _ in results])\n",
    "template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "prompt = template.format(context=contexts, question=query_text4)\n",
    "response = model.invoke(prompt)\n",
    "print(response)\n",
    "print(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no mention of elephants or their ability to drive in the provided context. The text appears to be discussing buses and a study on machine learning models for predicting vehicle condition, with no reference to elephants whatsoever.\n"
     ]
    }
   ],
   "source": [
    "results = database.similarity_search_with_relevance_scores('Are elephants capable of driving?', k=4)\n",
    "contexts = '\\n\\n'.join([result.page_content for result, _ in results])\n",
    "template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "prompt = template.format(context=contexts, question='Are elephants capable of driving?')\n",
    "response = model.invoke(prompt)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
